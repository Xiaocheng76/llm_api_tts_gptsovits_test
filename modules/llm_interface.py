# modules/llm_interface.py
import requests

def call_llm(prompt):
    headers = {
        "Authorization": "de3MaxMVwIqHZTSxsqVcRVxvmdaZDMUK",  # ğŸ‘ˆ æŠŠé€™è£¡æ›æˆä½ çš„
        "Content-Type": "application/json"
    }
    payload = {
        "model": "google/gemma-3-12b-it",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æœ‰æº«åº¦çš„AIåŠ©ç†ã€‚"},
            {"role": "user", "content": prompt}
        ]
    }

    response = requests.post("https://api.deepinfra.com/v1/openai/chat/completions",
                             headers=headers, json=payload)
    return response.json()["choices"][0]["message"]["content"]
